{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, List, Union, Dict\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTranslator(object):\n",
    "    \"\"\"\n",
    "    Data Translator Class.\n",
    "    Uses the Google API library.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._translator = GoogleTranslator(source=\"auto\", target=\"en\")\n",
    "\n",
    "    def translate(self, text_batch: Sequence[str]) -> List[str]:\n",
    "        if not isinstance(text_batch, (list, tuple, set)):\n",
    "            raise ValueError(\"An iterable it's expected\")\n",
    "\n",
    "        translated_batch = self._translator.translate_batch(\n",
    "            batch=text_batch\n",
    "        )\n",
    "\n",
    "        return translated_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(folder: str, size_of_batch: int) -> Dict[str, pd.DataFrame]:\n",
    "    # Path to folders.\n",
    "    path = pathlib.Path(folder)\n",
    "\n",
    "    # Search all csv in the current directory.\n",
    "    files = [f.name for f in path.glob('**/*.csv')]\n",
    "\n",
    "    # Dict of pd.DataFrames.\n",
    "    dataframes = {}\n",
    "    \n",
    "\n",
    "    # Iterate over the files.\n",
    "    for file in files:\n",
    "        f = next(path.glob(f'{file}'))\n",
    "        # Read the csv file.\n",
    "        data = pd.read_csv(f, encoding='iso-8859-1')\n",
    "        # Drop non values in rating.\n",
    "        data = data[data['Rating'].isna() == False]\n",
    "        # Create auxiliar labels.\n",
    "        data['labels'] = data['Rating'].astype(str)\n",
    "        # Sample random.\n",
    "        data = data.sample(n=size_of_batch, weights='labels')\n",
    "        # Reset index.\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        # Format the columns.\n",
    "        data.columns = data.columns.str.lower()\n",
    "        # Drop the columns without comment.\n",
    "        data = data[data['comment'].isna() == False]\n",
    "        # Handle the datatypes.\n",
    "        data['comment'] = data['comment'].apply(lambda x: str(x).strip())\n",
    "        # Match all string/numeric ones.\n",
    "        pattern = '^[0-9]+$'\n",
    "        # Filter out the number strings.\n",
    "        data = data[data['comment'].str.contains('^[0-9]+$') == False]\n",
    "        # Sort the values by date.\n",
    "        # data = data.sort_values(by=['date']).reset_index(drop=True)\n",
    "\n",
    "        if size_of_batch > data.shape[0]:\n",
    "            size_of_batch = data.shape[0]\n",
    "\n",
    "        # Text batch.\n",
    "        text_batch = data['comment'].to_list()[0:size_of_batch]\n",
    "        # Instance the DataTranslator\n",
    "        translator = DataTranslator()\n",
    "        # Translate the data.\n",
    "        text_translated = translator.translate(text_batch=text_batch)\n",
    "\n",
    "        # Create the translated DataFrame.\n",
    "        translated_data = pd.DataFrame(data={'comment_translated': text_translated})\n",
    "        # Join to transformed DataFrame.\n",
    "        trans_data = data.iloc[0:size_of_batch].join(translated_data)\n",
    "\n",
    "        dataframes.update(\n",
    "            {\n",
    "                file: trans_data\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_translated = data_pipeline(folder=\"/home/aargaez/downloads/Datathon/data_test\", size_of_batch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_translated['Feed_back_button.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, data in data_translated.items():\n",
    "    data.to_csv(f'Translated_{label}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
